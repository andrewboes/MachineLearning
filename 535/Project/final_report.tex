% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage{comment}
\usepackage{url}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\xhdr}[1]{\vspace{3pt}\noindent\textbf{#1}}
%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{AI535}
\def\confYear{S2022}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{ Using Transfer Learning To Count Recreational Fishing Boats }

\author{Andrew Boes \hspace{30pt} Jesse Swartz \\
Oregon Department of Fish and Wildlife\\
{\tt\small \{andrew.j.boes, jesse.l.swartz\}@odfw.oregon.gov}
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
   The Oregon Department of Fish and Wildlife (ODFW) has setup cameras at several ports and harbors on the Oregon Coast. Currently this video is reviewed by employees, called samplers, to get counts of boats that are going out fishing. This information, combined with other information, is used to get what is called a Catch Effort Estimation which in turn is used to open or close fisheries. Automating this process would expand the count to all days of the week, broaden it to other ports and free up samplers to spend more time getting biological fish data.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Background}

While more and more Oregonians go outside, the number of fishing licenses and number of fish available to catch has been declining for the past few years \cite{ODFW_Annual}. ODFW spends a considerable amount of resources analyzing this behavior to maintain the health of the fish population. Due to recent advances in technology such as better 4G cell phone coverage on the Oregon Coast and SpaceX Starlink satellite broadband internet, the Marine Resources Program (MRP) of ODFW is now able to upload videos at three ports. Previously, these ports were either counted in person or VHS tapes were driven to a central location to be reviewed. Starting in 2022 the ports of Newport, Depot Bay, and Charleston have cameras that upload video every two hours to the cloud. This availability allows us to start working on automating the daily boat count.\\[-5pt]

\section{Introduction}

We propose using transfer learning to identify boats in images taken from port surveillance cameras. We will then use semantic segmentation and multi-object tracking (MOT) over a series of frames to identify individual boats which will allow us to get the count for a given time period. Once the count is complete we can compare our results to the data that is obtained by port samplers.

\subsection{Classifying}

After the relatively simple task of parsing the video into images, the next thing to do is to perform instance segmentation on each frame of the video. There are many comprehensive comparisons of different detection methods \cite{pytorch_models} but we chose to compare a few that are available as pre-trained PyTorch models on our data, using our hardware. [MORE]

\subsection{Recreational vs. Non-recreational}

 As the port sampler count is only recreational boats, we will need to filter the non-recreational boats out. Publicly available datasets don't have distinguish between the two types of boats so we plan on using zero-shot transfer learning to remove non-recreational (commercial, charter, Coast Guard, etc.) boats from the count. The difference between recreational and non-recreational boats is typically very obvious. However there are a few edge cases where they are very similar.

\subsection{Multi-Object Tracking}

For the most difficult part of this project, MOT, we plan on trying three different approaches. This will include a heuristic based tracking algorithm and using the hidden state of one of the networks to track the objects. In addition, we'll try counting the boats without tracking by passing the results of our semantic segmentation over a series of frames to a Long-Short Term Memory (LSTM) network.

\begin{figure*}[t]
  \centering
    \includegraphics[scale=.4]{roughFlow.png}
    \caption{A. Video is captured by cameras. B. Every two hours data is uploaded using SpaceX Starlink satellite internet. C.-D. Once the video is received it is parsed into sequential frames. E. Semantic segmentation is performed using Mask RCNN pre-trained model. F. Get instances from segmentation and group them together. Once grouped, classify all of the images as either recreational and non-recreational. The classification of the highest value wins. G. Record count of recreational boats in 30 minute intervals.}
    \label{fig:pipline}
  \hfill
\end{figure*}

\section{Related Work}

We found some research in marina monitoring systems \cite{marina_boatdetector} and even a commercial solution that uses cameras to determine if marina slips are available \cite{Nuvis}. In addition there was a Kaggle competition to find ships in satellite images \cite{kaggle_ship_detection, Stofa_2020}. While these did provide some insight to what others were doing in this field, we found their approaches (radar and sonar) and datasets (high altitude airplanes and satellites) weren't applicable to our work.

There was one abstract of a paper that we found that looked promising \cite{UCalagary}. It looked like their goal was nearly identical to ours but our search for the paper or any other details came up empty. While we would like to know their results, finding this validated the need for automated boat counting!

As stated above, the most complicated part of this project is tracking the object from frame to frame. Recently, tracking-by-detection has become the standard paradigm for MOT. The main idea is to split the problem into two parts: object detection and data association. Over the past few years, object detection has seen great improvement thanks to deep learning techniques\cite{https://doi.org/10.48550/arxiv.1506.01497}, but data association remains a challenge for multi-object tracking.

\section{Methodology}

Figure \ref{fig:pipline} demonstrates a high level view of our data flow. 

As we knew MOT was going to be the crux of our success we split our efforts into three different approaches explained below.

\subsection{SORT}

To get the final count we started by reviewing several tracking algorithms and decided to start with SORT \cite{Bewley_2016}. We thought this was a good place to start as the 'S' stands for simple. 

\subsection{Counting-by-tracking-by-detection}

The next effort is to use object detection to track the boats then associate detections in adjacent frames to get a count. Mask RCNN handles instance identification in an ordered list fashion.  Two sequential frames with multiple instances will reclassify in the same order.  Using this baseline, we will try to create a set of rules to ensure accuracy on counting and gaining some information on the trajectory of identified boats by calculating movement speed based on image offsets, count frames that the boat instance occurred in, and proof check that it had a realistic movement off-screen, and traveled an appropriate distance to get there (which helped disregard issues in classification such as occasional double counting overlaps and false positives).  During the span of frame counts, we again referred back to the image classification per frame. One of our stretch goals was to get a count of people on board to do this we count the max frame of any people classified within the bounding box of the boat to get an approximate passenger count. Also using this trajectory speed, the width of the camera observation, and the y position, we are able to calculate the speed of the boat. 

\begin{figure*}[t]
  \centering
    \includegraphics[scale=.75]{WinonaJ.png}
    \caption{Red outline is the actual box}
    \label{fig:WinonaJ}
  \hfill
\end{figure*}
\section{Results} 
\subsection{Counting without tracking}

As we don't actually need to track the boats in our video, we propose creating an LSTM where the input is boat centroid locations and the output is the running total. We don't have any data for this approach so we'll make some assumptions about a large bulk of the data. The first assumption is that the majority of the boats travel directly from one side of the screen to the other. Second, depending on speed, boats occur in four to eight frames total. Third, there are never more that five boats in any given frame. And finally, we'll use a classification structure and allow outputs from 0 to 10. 

Making these assumptions allows us to generate data to train the network. We'll generate lines that have a small slope and a wide range of values for the y-intercept. Then we'll sample these lines four to eight times and add some noise to the input and output. These samples will stand in for the boat centroid and each line will represent a boat which is our classification for this network.


\subsection{Classifying}

Table \ref{tab:ModelPerf} shows the performance of a few different pre-trained models we tested. These were tested on an older server without a GPU so the raw times aren't important but the relative performance is. For accuracy, we manually created a test set of 387 images with bounding boxes and compared our bounding boxes to the predicted bounding boxes using intersection over union.

We didn't find that outputs from different models got the exact same bounding boxes so there may be some room boost accuracy with ensemble learning.

This effort was in parallel with our other efforts so we ended up using Mask RCNN in our tracking but will explore using YOLO v5 in the future.

\begin{table}[t]
  \centering
  \begin{tabular}{@{}lc@{}lc@{}}
    \toprule
    Model & Accuracy\nobreakspace\nobreakspace\nobreakspace & \nobreakspace\nobreakspace Time \\
    \midrule
    YOLO v5\cite{pytorch_yolov5} & 69\% & 1m 24s \\
    Faster RCNN\cite{pytorch_fasterrcnn_resnet50_fpn} & 66\% & 31m 14.5s \\
    Mask RCNN\cite{pytorch_maskrcnn_resnet50_fpn} & 78\% & 32m 46.5s\\
    Retina Net\cite{pytorch_retinanet_resnet50_fpn} & 69\% & 33m 48s\\
    \bottomrule
  \end{tabular}
  \caption{YOLO FTW}
  \label{tab:ModelPerf}
\end{table}


\subsection{Recreational vs. Non-recreational}

The dataset used for training our system was professionally labeled by the MRP staff in Newport. This consisted of 100 training images and 50 validation images. The initial weights we used were from RESNET152 \cite{PyTorch_RESNET152}. We didn't spend too much time hyperparameter tuning and didn't do any data augmentation. Our best train accuracy was 96\% and our best validation accuracy was 91\%. We were very happy with those numbers given how much effort they were to produce and are certain we can achieve a higher score with some tuning and more data.

As our results show, many recreational and non-recreational boats are very easy to differentiate however there is one type that was frequently misclassified. Many large recreational boats look very similar to charter boats. The difference being that recreational boats usually have a larger cabin whereas charter boats have a larger working platform near the stern. For Figures \ref{fig:non_rec_boat} and \ref{fig:rec_boat}, we had to ask MRP what makes Figure \ref{fig:non_rec_boat} a non-recreational and the response indicated that they personally identified the boat as belonging to a charter company.

\begin{figure}
 \center
  \includegraphics[scale=.41]{non_rec_boat_ex.png}
  \caption{Non-recreational boat}
  \label{fig:non_rec_boat}
\end{figure}

\begin{figure}
 \center
  \includegraphics[scale=.47]{rec_boat_ex.png}
  \caption{Recreational boat}
  \label{fig:rec_boat}
\end{figure}

\subsection{SORT}

While the implementation of the SORT algorithm was fairly straight forward, we found that as it relied on Kalman filter it was prone to drifts that were difficult to recover from \cite{10.1007/978-3-540-24670-1_3}. As edge cases piled up, such as boats leaving and entering near the same location on adjacent frames and smaller boats going behind large boats, the SORT tracker didn't perform very well. Our results had frequent double counting and losing instances.

\subsection{Counting-by-tracking-by-detection}

Talk about edge cases? Occlusion? Austin powers boat?

\subsection{Counting without tracking}

The results of our LSTM were very promising. It did take quite a bit of hyperparameter tuning but we were able to achieve validation accuracy of 94\%. As our counting by tracking efforts were also positive we focused a lot of our efforts on that and didn't test the LSTM with real data. Overall this was a very positive outcome and we will continue to pursue it.

\subsection{Putting it all together}

<Comparing our count count to MRP count/?

\section{Future Work}

There are a number of stable models available from PyTorch and there are quite a few models that are available in the community. In our test we were only able to compare one community model (YOLO v5 \cite{pytorch_yolov5}) and this is because the image inputs and model outputs are different between them all. Some of the differences are simple (different expected transforms) others are more complicated (output data structure, rectangle format) and few of them offer comprehensive documentation on their use. This makes adding each new model laborious so we arbitrarily drew the line at four. In the future we hope to add more of these to our test results.

Once the application is running in production, if a boat's classification is close to the middle between recreational and non-recreational we'll flag it for review by MRP. Periodically we'll retrain the classifier with the latest inputs.

As we often say when developing a project, make it work then make it fast. Currently we're reading video with one frame per second and it takes us over one second to classify that that frame. We believe there is a lot of room to improve our performance. Some preliminary results show that lowering the resolution and other image transforms improve performance by 4x while not hurting accuracy. Also, we'd like to try YOLO v5 in our counting-by-tracking-by-detection method and seem how that affects performance and accuracy.

\begin{comment}

%------------------------------------------------------------------------




\begin{table}[t]
  \centering
  \begin{tabular}{@{}lc@{}}
    \toprule
    Method & Frobnability \\
    \midrule
    Theirs & Frumpy \\
    Yours & Frobbly \\
    Ours & Makes one's heart Frob\\
    \bottomrule
  \end{tabular}
  \caption{Results.   Ours is better.}
  \label{tab:example}
\end{table}
\end{comment}
%-------------------------------------------------------------------------





%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
