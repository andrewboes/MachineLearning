% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage{comment}
\usepackage{url}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\xhdr}[1]{\vspace{3pt}\noindent\textbf{#1}}
%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{AI535}
\def\confYear{S2022}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{ Using Transfer Learning To Count Recreational Fishing Boats }

\author{Andrew Boes \hspace{30pt} Jesse Swartz \\
Oregon Department of Fish and Wildlife\\
{\tt\small \{andrew.j.boes, jesse.l.swartz\}@odfw.oregon.gov}
}
\maketitle

%%%%%%%%% ABSTRACT a change
\begin{abstract}
   The Oregon Department of Fish and Wildlife (ODFW) has set up cameras at several ports and harbors on the Oregon Coast. Currently this video is reviewed by employees, called port samplers, to get counts of boats that are going out fishing. This information, combined with other information, is used to get what is called a Catch Effort Estimation which in turn is used to open or close fisheries. Automating this process would expand the count to all days of the week, broaden it to other ports and free up port samplers to spend more time getting biological fish data.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Background}

While more and more Oregonians go outside, the number of fishing licenses and number of fish available to catch has been declining for the past few years \cite{ODFW_Annual}. ODFW spends a considerable amount of resources analyzing this behavior to maintain the health of the fish population. Due to recent advances in technology such as better 4G cell phone coverage on the Oregon Coast and SpaceX Starlink satellite broadband internet, the Marine Resources Program (MRP) of ODFW is now able to upload videos at three ports. Previously, these ports were either counted in person or VHS tapes were driven to a central location to be reviewed. Starting in 2022 the ports of Newport, Depot Bay, and Charleston have cameras that upload video every two hours to the cloud. This availability allows us to begin the process of automating the daily boat count.\\[-5pt]

\section{Introduction}

We propose using transfer learning to identify boats in images taken from port surveillance cameras. We will then use semantic segmentation and multi-object tracking (MOT) over a series of frames to identify individual boats which will allow us to get the count for a given time period. Once the count is complete we can compare our results to the data that is obtained by port samplers.

\subsection{Classifying}

After the relatively simple task of parsing the video into images, the next thing to do is to perform instance segmentation on each frame of the video. There are many comprehensive comparisons of different detection methods \cite{pytorch_models} but we chose to compare a few that are available as pre-trained PyTorch models on our data, using our hardware.

\subsection{Recreational vs. Non-recreational}

 As the port sampler count is only recreational boats, we will need to filter the non-recreational boats out. Publicly available data sets do not distinguish between the two types of boats so we plan on using zero-shot transfer learning to remove non-recreational (commercial, charter, Coast Guard, etc.) boats from the count. The difference between recreational and non-recreational boats is typically very obvious. However there are a few edge cases where they are very similar.

\subsection{Multi-Object Tracking}

For the most difficult part of this project, MOT, we plan on trying three different approaches. This will include a heuristic based tracking algorithm and using the hidden state of one of the networks to track the objects. In addition, we will try counting the boats without tracking by passing the results of our semantic segmentation over a series of frames to a Long-Short Term Memory (LSTM) network.

\begin{figure*}[t]
  \centering
    \includegraphics[scale=.4]{roughFlow.png}
    \caption{(A) Video is captured by cameras. (B) Every two hours data is uploaded using SpaceX Starlink satellite internet. (C)-(D) Once the video is received it is parsed into sequential frames. (E) Semantic segmentation is performed using Mask RCNN pre-trained model. (F) Get instances from segmentation and group them together. Once grouped, classify all of the images as either recreational and non-recreational. The classification of the highest value wins. (G) Record count of recreational boats in 30 minute intervals.}
    \label{fig:pipline}
  \hfill
\end{figure*}

\section{Related Work}

We found some research in marina monitoring systems \cite{marina_boatdetector} and even a commercial solution that uses cameras to determine if marina slips are available \cite{Nuvis}. In addition there was a Kaggle competition to find ships in satellite images \cite{kaggle_ship_detection, Stofa_2020}. While these did provide some insight to what others were doing in this field, we found their approaches (radar and sonar) and datasets (high altitude airplanes and satellites) weren't applicable to our work.

There was one abstract of a paper that we found that looked promising \cite{UCalagary}. It looked like their goal was nearly identical to ours but our search for the paper or any other details came up empty. While we would like to know their results, finding this validated the need for automated boat counting!

As stated above, the most complicated part of this project is tracking the object from frame to frame. Recently, tracking-by-detection has become the standard paradigm for MOT. The main idea is to split the problem into two parts: object detection and data association. Over the past few years, object detection has seen great improvement thanks to deep learning techniques\cite{https://doi.org/10.48550/arxiv.1506.01497}, but data association remains a challenge for multi-object tracking.

\section{Methodology}

Figure \ref{fig:pipline} demonstrates a high level view of our data flow. 

As we knew MOT was going to be the crux of our success we split our efforts into three different approaches explained below.

\subsection{SORT}

To get the final count we began by reviewing several tracking algorithms and decided to start with SORT \cite{Bewley_2016}. We thought this was a good place to start as the `S' stands for simple.  The integration to our dataset was simple enough, but the results were sporadic and not reliable to derive a final count. Reliable instance tracking is crucial to determining an exact count of unique identifications.

\subsection{Counting-by-tracking-by-detection}

In an effort to improve instance detection within the bounds of our specific applications, we decided to create our own instance identification tracking by relying on segmentation masks.  We found the brilliant MaskRCNN, which uses a ResNet101 backbone to derive a list of rois, bounding boxes, and simple classifications.

Identifying an instance on a single frame only requires the simple  segmentation of classifications.  Retaining an instance between multiple frame classifications is what posed a larger challenge, requiring dynamic identifiers to retain, omit, and introduce new instances as the temporal state of the scene progresses.  

To construct a proper result set, we need to process the results from our instance segmentation and derive a set of behaviors that satisfies the potential actions that an identified boat will take across the scene.  This will allow us to represent and track outcomes, as well as create edge case detections to deal with the unfortunately sporadic nature of image classification over long periods of time.


\subsection{Counting without tracking}

As an alternative to processing boat results, another option would be an LSTM where the input is boat centroid locations and the output is the running total. We do not have any data for this approach so we will make some assumptions about a large bulk of the data. The first assumption is that the majority of the boats travel directly from one side of the screen to the other. Second, depending on speed, boats occur in four to eight frames total. Third, there are never more that five boats in any given frame. And finally, we will use a classification structure and allow outputs from 0 to 10. 

Making these assumptions allows us to use mock data to train the network. We will generate lines that have a small slope and a wide range of values for the y-intercept. Then we will sample these lines four to eight times and add some noise to the input and output. These samples will stand in for the boat centroid and each line will represent a boat which is our classification for this network.

\begin{figure*}[t]
  \centering
    \includegraphics[scale=.75]{WinonaJ.png}
    \caption{Red box is the value from the test data.}
    \label{fig:WinonaJ}
  \hfill
\end{figure*}
\section{Results} 

\subsection{Classifying}

Table \ref{tab:ModelPerf} shows the performance of a few different pre-trained models we tested. These were tested on an older server without a GPU so the raw times are not important but the relative performance is. For accuracy, we manually created a test set of 387 images with bounding boxes and compared our bounding boxes to the predicted bounding boxes using intersection over union.

We did not find that outputs from different models produced the exact same bounding boxes so there may be some room boost accuracy with ensemble learning. For an example, see \ref{fig:WinonaJ}.

This effort was in parallel with our other efforts so we ended up using Mask RCNN in our tracking but will explore using YOLO v5 in the future.

\begin{table}[t]
  \centering
  \begin{tabular}{@{}lc@{}lc@{}}
    \toprule
    Model & Accuracy\nobreakspace\nobreakspace\nobreakspace & \nobreakspace\nobreakspace Time \\
    \midrule
    YOLO v5\cite{pytorch_yolov5} & 69\% & 1m 24s \\
    Faster RCNN\cite{pytorch_fasterrcnn_resnet50_fpn} & 66\% & 31m 14.5s \\
    Mask RCNN\cite{pytorch_maskrcnn_resnet50_fpn} & 78\% & 32m 46.5s\\
    Retina Net\cite{pytorch_retinanet_resnet50_fpn} & 69\% & 33m 48s\\
    \bottomrule
  \end{tabular}
  \caption{}
  \label{tab:ModelPerf}
\end{table}


\subsection{Recreational vs. Non-recreational}

The dataset used for training our system was professionally labeled by the MRP staff in Newport. This consisted of 100 training images and 50 validation images. The initial weights we used were from RESNET152 \cite{PyTorch_RESNET152}. We did not spend too much time hyperparameter tuning and did not implement any data augmentation. Our best training accuracy was 96\% and our best validation accuracy was 91\%. We were very happy with those numbers given how much effort they were to produce and are certain we can achieve a higher score with some tuning and more data.

As our results show, many recreational and non-recreational boats are very easy to differentiate however there is one type that was frequently misclassified. Many large recreational boats look very similar to charter boats. The difference being that recreational boats usually have a larger cabin whereas charter boats have a larger working platform near the stern. For Figures \ref{fig:non_rec_boat} and \ref{fig:rec_boat}, we had to ask MRP what makes Figure \ref{fig:non_rec_boat} a non-recreational and the response indicated that they personally identified the boat as belonging to a charter company.

\begin{figure}
 \center
  \includegraphics[scale=.41]{non_rec_boat_ex.png}
  \caption{Non-recreational boat}
  \label{fig:non_rec_boat}
\end{figure}

\begin{figure}
 \center
  \includegraphics[scale=.47]{rec_boat_ex.png}
  \caption{Recreational boat}
  \label{fig:rec_boat}
\end{figure}

\subsection{SORT}

While the implementation of the SORT algorithm was fairly straightforward, we found that as it relied on Kalman filter it was prone to drifts that were difficult from which to recover \cite{10.1007/978-3-540-24670-1_3}. As edge cases piled up, such as boats leaving and entering near the same location on adjacent frames and smaller boats going behind large boats, the SORT tracker did not perform very well. Our results had frequent double counting and losing instances.

\subsection{Counting-by-tracking-by-detection}

Using Mask RCNN in conjunction with our transfer learning model created a great foundation for processing the behavior driven actions of our projected boat instances.  

Our framework for instance identification was written with the idea of identifying the different states or current status of a boat.  A trajectory of a boat is determined by its centroid's movement across multiple frames.  Speed can be determined by difference in position.  Using these factors, we are able to distinguish and eliminate false positives that occur in the neural network identification results, such as double/overlapping bounding boxes and `pop-in' instances that would severely affect the instance count.

This also allows us to fine tune a set of object oriented parameters for restricting instance detection, such as setting boundaries for new instance introductions (a boat never enters in the middle of the frame), frame count thresholds for ensuring the number of frames used for a trajectory is realistic, and movement side thresholds for predictive analysis on when a boat is intending to leave the frame.  All of these parameters can be set and tuned to allow for another layer of accuracy.

Retaining a set of frames for a given instance allows for some additional performance reinforcement in our individual classification as well.  Rather then identify if a single instance of a boat is recreational or commercial, we are able to look back at all instances, and find a maximum agreed classification.  The same goes for counting the number of passengers; we can look back and find which frame shows the most identified instances of people and make decisions based on a set of temporal data.

Overall, this methodology has allowed us to correct any issues and seems to be an effective method for reliable accuracy.

\subsection{Counting without tracking}

The results of our LSTM were also very promising. It did take quite a bit of hyperparameter tuning, but we were able to achieve validation accuracy of 94\%. As our object tracking efforts were also positive we focused a lot of our efforts on that and did not test the LSTM with real data. Overall this was a very positive outcome and we will continue to pursue it.

\subsection{Putting it all together}

Our first efforts at comparing our output to test data did not go very well but they did help us identify quite a few edge cases. For a large portion of time periods we were able to achieve 100\% accuracy, for others it was 0\%. Overall, we were encouraged by this result as the vast majority of footage is just water or water with a single boat. By the time of our due date we were not able to run the latest version of our application for an entire days worth of video. However we are confident that we have achieved a much improved accuracy as we have tested it on several edge cases. There are two that standout: one is a boat turning around that hovers on the edge of the frame for several frames that was getting miscounted and another was one of the few times several recreational boats are in frame with a non-recreational boat. Both of these instances were fixed with our latest code. Figure \ref{fig:sequence} contains the output of one such scenario. We have animated these scenarios and links are available in the More Information section. 

\begin{figure}
 \center
  \includegraphics[scale=.8]{Sequence2.png}
  \caption{Each boat is assigned an ID and a classification. This image has annotations with those values.}
  \label{fig:sequence}
\end{figure}

\section{Future Work}

There are a number of stable models available from PyTorch and there are quite a few models that are available in the community. In our test we were only able to compare one community model (YOLO v5 \cite{pytorch_yolov5}) and this is because the image inputs and model outputs are different between them all. Some of the differences are simple (different expected transforms) others are more complicated (output data structure, rectangle format) and few of them offer comprehensive documentation on their use. This makes adding each new model laborious so we arbitrarily drew the line at four. In the future we hope to add more of these to our test results.

Once the application is running in production, if a boat's classification is close to the middle between recreational and non-recreational we will flag it for review by MRP. Periodically we will retrain the classifier with the latest inputs.

As we often say when developing an application, make it work then make it fast. Currently we are reading video with one frame per second and it takes us over one second to classify that that frame. We believe there is a lot of room to improve our performance. Some preliminary results show that lowering the resolution, normalizing the images and other image transforms improve performance by 4x while not hurting accuracy. Also, we would like to try YOLO v5 in our counting-by-tracking-by-detection method and see how that affects performance and accuracy.

\section{More Information}

\begin{itemize}
    \renewcommand\labelitemi{--}
    \item Code to compare different classification methods: \url{https://github.com/andrewboes/MachineLearning/blob/master/535/Project/PreTrainedTestHarness.py}
    \item Code to process videos, get boat segments, and save them in different directories: \url{https://github.com/andrewboes/MachineLearning/blob/master/535/Project/ProcessImages.py}
    \item Code for line counting LSTM: \url{https://github.com/andrewboes/MachineLearning/blob/master/535/Project/TrackCountingLSTM.py} 
    \item GIF of best output using SORT to count boats: \url{https://github.com/andrewboes/MachineLearning/blob/master/535/Project/ProgressGifs/20220520T1440\%20SORT\%20Tracking.gif}
    \item GIF of edge case with turning boat: \url{https://github.com/andrewboes/MachineLearning/blob/master/535/Project/ProgressGifs/BoatTurn-instance.gif}
    \item GIF of complicated scenario with recreational and non-recreational boats: \url{https://github.com/andrewboes/MachineLearning/blob/master/535/Project/ProgressGifs/Instances\%20Classified.gif}
    \item Colab notebook puting it all together: \url{https://colab.research.google.com/drive/1eumK3l4zKXiu7IGFOe0yQUvSsBSlPAVv}
\end{itemize}

\begin{comment}

%------------------------------------------------------------------------




\begin{table}[t]
  \centering
  \begin{tabular}{@{}lc@{}}
    \toprule
    Method & Frobnability \\
    \midrule
    Theirs & Frumpy \\
    Yours & Frobbly \\
    Ours & Makes one's heart Frob\\
    \bottomrule
  \end{tabular}
  \caption{Results.   Ours is better.}
  \label{tab:example}
\end{table}
\end{comment}
%-------------------------------------------------------------------------





%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
